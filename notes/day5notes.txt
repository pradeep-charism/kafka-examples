
	Source Connector		    	(Calculate salary)	   	  	Sink Connector
Mysql table----------------------------->Kafka Topic 1------>Streaming App------>Kafka Topic 2--------------------------------------->Cassandra db
	  (Extract)		mysql-topic-employee(Transform)   	cassandra-topic-employee   (Load)



mysql-cassandra etl pipeline

1. Download the cassandra connector from https://github.com/lensesio/stream-reactor/releases/download/2.1.3/kafka-connect-cassandra-2.1.3-2.5.0-all.tar.gz 
and extract.

2. copy the kafka-connect-cassandra-....jar file to kafka\libs directory.

3. create mysql-source-connector-etl.properties in kafka\config directory with the following content.

name=mysql-for-etl
connector.class=io.confluent.connect.jdbc.JdbcSourceConnector
tasks.max=10

connection.url=jdbc:mysql://192.168.25.133:3306/trainingdb?user=root&password=root
table.whitelist=employee

mode=incrementing
incrementing.column.name=emp_id

topic.prefix=mysql-topic-


4. create cassandra-sink-connector-etl.properties in kafka\config directory with the following content.



5. create the employee domain class with the following content.


package com.jpmc.training.domain;

public class Employee {
	private int emp_id;
	private String emp_name;
	private String designation;
	private int salary;
	public int getEmp_id() {
		return emp_id;
	}
	public void setEmp_id(int emp_id) {
		this.emp_id = emp_id;
	}
	public String getEmp_name() {
		return emp_name;
	}
	public void setEmp_name(String emp_name) {
		this.emp_name = emp_name;
	}
	public String getDesignation() {
		return designation;
	}
	public void setDesignation(String designation) {
		this.designation = designation;
	}
	public int getSalary() {
		return salary;
	}
	public void setSalary(int salary) {
		this.salary = salary;
	}
	public Employee(int emp_id, String emp_name, String designation, int salary) {
		super();
		this.emp_id = emp_id;
		this.emp_name = emp_name;
		this.designation = designation;
		this.salary = salary;
	}
	public Employee() {
		super();
		// TODO Auto-generated constructor stub
	}
	
	
}





kcql-kafka cassandra query language.


6. Create a serializer and deserializer for Employee class.

7. Create the Serde class.

User defined Serde should implement an interface called Serde.

8. Create the streaming app.
9. Start the connector with the following command

bin\windows\connect-standalone.bat config\connect-standalone.properties config\mysql-source-connector-etl.properties config\cassandra-sink-connector-etl.properties


KTable is an abstraction for streaming aggregations.


Ksql provides a sql based interface for interacting with kafka.
It is available with confluent kafka.


Kafka Cluster:

Kafka cluster consists of one or more servers(kafka brokers) running concurrently. 
All brokers which connect to same zookeeper  will be part of the same cluster.

	broker-id	port	logs-dir
broker-1	     1	9091	/tmp/broker-1	
broker-2	     2	9092	/tmp/broker-2
broker-3	     3	9093	/tmp/broker-3

1. create 3 copies of server.properties and name them server-1.properties,server-2.properties and server-3.properties respectively.

In each of these properties files, modify the following properties

broker.id
listener
log-dirs


2. Create 3 batch fiels in kafka directory to start these servers

sample content

kafka\start-server1.bat

start "Server-1" bin\windows\kafka-server-start.bat config\server-1.properties


Leader:

Each partition has one server acting as the leader. The leader handles all read and write requests for the partition
while the followers passively replicate the leader.

ISR-- In Sync Replicas

Kafka Security:

kafka-acls utility is used to assign only some specific users to publish/ consume from the topic.

JAAS --- Java Authentication and Authorization Service Api.





